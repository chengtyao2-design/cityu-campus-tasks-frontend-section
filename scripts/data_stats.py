#!/usr/bin/env python3
"""
æ•°æ®ç»Ÿè®¡åˆ†æè„šæœ¬
åˆ†æ tasks.csv å’Œ task_kb.jsonl çš„å†…å®¹å’Œè´¨é‡
"""

import csv
import json
from collections import Counter
from typing import Dict, List, Any, Set
import os

def analyze_tasks_csv(file_path: str) -> Dict[str, Any]:
    """åˆ†æ tasks.csv æ–‡ä»¶"""
    if not os.path.exists(file_path):
        return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}
    
    stats = {
        "total_tasks": 0,
        "categories": Counter(),
        "difficulties": Counter(),
        "locations": set(),
        "npcs": set(),
        "courses": set(),
        "durations": [],
        "points": [],
        "field_stats": {}
    }
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for row in reader:
                stats["total_tasks"] += 1
                
                # ç»Ÿè®¡åˆ†ç±»
                if row.get("category"):
                    stats["categories"][row["category"]] += 1
                
                # ç»Ÿè®¡éš¾åº¦
                if row.get("difficulty"):
                    stats["difficulties"][row["difficulty"]] += 1
                
                # ç»Ÿè®¡æ—¶é•¿
                if row.get("estimated_duration"):
                    try:
                        duration = int(row["estimated_duration"])
                        stats["durations"].append(duration)
                    except ValueError:
                        pass
                
                # ç»Ÿè®¡ç§¯åˆ†
                if row.get("points"):
                    try:
                        points = int(row["points"])
                        stats["points"].append(points)
                    except ValueError:
                        pass
                
                # æ”¶é›†å”¯ä¸€å€¼
                if row.get("location_name"):
                    stats["locations"].add(row["location_name"])
                if row.get("npc_id"):
                    stats["npcs"].add(row["npc_id"])
                if row.get("course_code"):
                    stats["courses"].add(row["course_code"])
                
                # å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡
                for field, value in row.items():
                    if field not in stats["field_stats"]:
                        stats["field_stats"][field] = {"filled": 0, "empty": 0}
                    
                    if value and value.strip():
                        stats["field_stats"][field]["filled"] += 1
                    else:
                        stats["field_stats"][field]["empty"] += 1
        
        # è®¡ç®—å¹³å‡å€¼
        if stats["durations"]:
            stats["avg_duration"] = sum(stats["durations"]) / len(stats["durations"])
            stats["min_duration"] = min(stats["durations"])
            stats["max_duration"] = max(stats["durations"])
        
        if stats["points"]:
            stats["avg_points"] = sum(stats["points"]) / len(stats["points"])
            stats["min_points"] = min(stats["points"])
            stats["max_points"] = max(stats["points"])
        
        # è®¡ç®—å­—æ®µå®Œæ•´ç‡
        for field_name, field_data in stats["field_stats"].items():
            total = field_data["filled"] + field_data["empty"]
            if total > 0:
                field_data["completion_rate"] = field_data["filled"] / total
        
        # è½¬æ¢é›†åˆä¸ºåˆ—è¡¨ä»¥ä¾¿JSONåºåˆ—åŒ–
        stats["locations"] = len(stats["locations"])
        stats["npcs"] = len(stats["npcs"])
        stats["courses"] = len(stats["courses"])
        
    except Exception as e:
        return {"error": f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}
    
    return stats

def analyze_task_kb_jsonl(file_path: str) -> Dict[str, Any]:
    """åˆ†æ task_kb.jsonl æ–‡ä»¶"""
    if not os.path.exists(file_path):
        return {"error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}
    
    stats = {
        "total_records": 0,
        "knowledge_types": Counter(),
        "task_ids": set(),
        "tags": Counter(),
        "field_stats": {}
    }
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                
                try:
                    record = json.loads(line)
                    stats["total_records"] += 1
                    
                    # ç»Ÿè®¡çŸ¥è¯†ç±»å‹
                    if record.get("knowledge_type"):
                        stats["knowledge_types"][record["knowledge_type"]] += 1
                    
                    # æ”¶é›†ä»»åŠ¡ID
                    if record.get("task_id"):
                        stats["task_ids"].add(record["task_id"])
                    
                    # ç»Ÿè®¡æ ‡ç­¾
                    if record.get("tags") and isinstance(record["tags"], list):
                        for tag in record["tags"]:
                            stats["tags"][tag] += 1
                    
                    # å­—æ®µå®Œæ•´æ€§ç»Ÿè®¡
                    for field, value in record.items():
                        if field not in stats["field_stats"]:
                            stats["field_stats"][field] = {"filled": 0, "empty": 0}
                        
                        if value is not None and str(value).strip():
                            stats["field_stats"][field]["filled"] += 1
                        else:
                            stats["field_stats"][field]["empty"] += 1
                
                except json.JSONDecodeError as e:
                    print(f"ç¬¬ {line_num} è¡ŒJSONè§£æé”™è¯¯: {e}")
                    continue
        
        # è®¡ç®—å­—æ®µå®Œæ•´ç‡
        for field_name, field_data in stats["field_stats"].items():
            total = field_data["filled"] + field_data["empty"]
            if total > 0:
                field_data["completion_rate"] = field_data["filled"] / total
        
        # è½¬æ¢é›†åˆä¸ºæ•°é‡
        stats["unique_task_ids"] = len(stats["task_ids"])
        stats["task_ids"] = list(stats["task_ids"])  # ä¿ç•™åˆ—è¡¨ç”¨äºéªŒè¯
        
    except Exception as e:
        return {"error": f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"}
    
    return stats

def print_analysis_report(tasks_stats: Dict[str, Any], kb_stats: Dict[str, Any]):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    print("=" * 60)
    print("ğŸ¯ CityU Campus Tasks æ•°æ®åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    
    # Tasks CSV åˆ†æ
    if "error" not in tasks_stats:
        print("\nğŸ“Š ä»»åŠ¡æ•°æ® (tasks.csv) åˆ†æ:")
        print(f"  æ€»ä»»åŠ¡æ•°: {tasks_stats['total_tasks']} ä¸ª")
        
        if tasks_stats.get("avg_duration"):
            print(f"  å¹³å‡æ—¶é•¿: {tasks_stats['avg_duration']:.1f} åˆ†é’Ÿ")
            print(f"  æ—¶é•¿èŒƒå›´: {tasks_stats['min_duration']}-{tasks_stats['max_duration']} åˆ†é’Ÿ")
        
        if tasks_stats.get("avg_points"):
            print(f"  å¹³å‡ç§¯åˆ†: {tasks_stats['avg_points']:.1f} åˆ†")
            print(f"  ç§¯åˆ†èŒƒå›´: {tasks_stats['min_points']}-{tasks_stats['max_points']} åˆ†")
        
        print(f"  ç‹¬ç‰¹åœ°ç‚¹: {tasks_stats['locations']} ä¸ª")
        print(f"  å…³è”NPC: {tasks_stats['npcs']} ä¸ª")
        print(f"  æ¶‰åŠè¯¾ç¨‹: {tasks_stats['courses']} é—¨")
        
        print("\n  ğŸ“ˆ åˆ†ç±»åˆ†å¸ƒ:")
        for category, count in tasks_stats["categories"].most_common():
            percentage = (count / tasks_stats["total_tasks"]) * 100
            print(f"    {category}: {count} ä¸ª ({percentage:.1f}%)")
        
        print("\n  ğŸšï¸ éš¾åº¦åˆ†å¸ƒ:")
        for difficulty, count in tasks_stats["difficulties"].most_common():
            percentage = (count / tasks_stats["total_tasks"]) * 100
            print(f"    {difficulty}: {count} ä¸ª ({percentage:.1f}%)")
    else:
        print(f"\nâŒ ä»»åŠ¡æ•°æ®åˆ†æå¤±è´¥: {tasks_stats['error']}")
    
    # Task KB JSONL åˆ†æ
    if "error" not in kb_stats:
        print(f"\nğŸ“š çŸ¥è¯†åº“æ•°æ® (task_kb.jsonl) åˆ†æ:")
        print(f"  æ€»è®°å½•æ•°: {kb_stats['total_records']} æ¡")
        print(f"  å…³è”ä»»åŠ¡: {kb_stats['unique_task_ids']} ä¸ª")
        
        print("\n  ğŸ§  çŸ¥è¯†ç±»å‹åˆ†å¸ƒ:")
        for knowledge_type, count in kb_stats["knowledge_types"].most_common():
            percentage = (count / kb_stats["total_records"]) * 100
            print(f"    {knowledge_type}: {count} æ¡ ({percentage:.1f}%)")
        
        print(f"\n  ğŸ·ï¸ æ ‡ç­¾ç»Ÿè®¡:")
        print(f"    æ€»æ ‡ç­¾æ•°: {len(kb_stats['tags'])} ä¸ª")
        print("    çƒ­é—¨æ ‡ç­¾:")
        for tag, count in kb_stats["tags"].most_common(10):
            print(f"      {tag}: {count} æ¬¡")
    else:
        print(f"\nâŒ çŸ¥è¯†åº“æ•°æ®åˆ†æå¤±è´¥: {kb_stats['error']}")
    
    # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
    if "error" not in tasks_stats and "error" not in kb_stats:
        print(f"\nğŸ”— æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥:")
        task_kb_coverage = (kb_stats['unique_task_ids'] / tasks_stats['total_tasks']) * 100
        print(f"  çŸ¥è¯†åº“è¦†ç›–ç‡: {task_kb_coverage:.1f}%")
        
        if task_kb_coverage >= 100:
            print("  âœ… æ‰€æœ‰ä»»åŠ¡éƒ½æœ‰å¯¹åº”çš„çŸ¥è¯†åº“æ¡ç›®")
        else:
            print("  âš ï¸ éƒ¨åˆ†ä»»åŠ¡ç¼ºå°‘çŸ¥è¯†åº“æ¡ç›®")
    
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ•°æ®è´¨é‡è¯„ä¼°å®Œæˆ")
    print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    # åˆ†ææ•°æ®æ–‡ä»¶
    tasks_stats = analyze_tasks_csv("data/tasks.csv")
    kb_stats = analyze_task_kb_jsonl("data/task_kb.jsonl")
    
    # æ‰“å°æŠ¥å‘Š
    print_analysis_report(tasks_stats, kb_stats)
    
    # ä¿å­˜è¯¦ç»†ç»Ÿè®¡åˆ°æ–‡ä»¶
    detailed_stats = {
        "tasks_analysis": tasks_stats,
        "knowledge_base_analysis": kb_stats,
        "generated_at": "2025-09-08T02:00:00+08:00"
    }
    
    try:
        with open("data/analysis_report.json", "w", encoding="utf-8") as f:
            json.dump(detailed_stats, f, ensure_ascii=False, indent=2, default=str)
        print(f"\nğŸ’¾ è¯¦ç»†åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: data/analysis_report.json")
    except Exception as e:
        print(f"\nâŒ ä¿å­˜åˆ†ææŠ¥å‘Šå¤±è´¥: {e}")

if __name__ == "__main__":
    main()